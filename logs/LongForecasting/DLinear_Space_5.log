Args in experiment:
Namespace(activation='gelu', batch_size=8, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='ai_competition_nonan.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=1, factor=1, features='S', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=30, learning_rate=0.0003, loss='mse', lradj='type1', model='DLinear', model_id='Space_5', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=30, root_path='./dataset/', seq_len=60, target='OT', test_flop=False, train_epochs=10, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : Space_5_DLinear_custom_ftS_sl60_ll30_pl30_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 2944
val 406
test 837
	iters: 100, epoch: 1 | loss: 0.2464214
	speed: 0.0051s/iter; left time: 18.2706s
	iters: 200, epoch: 1 | loss: 0.6464957
	speed: 0.0012s/iter; left time: 4.0820s
	iters: 300, epoch: 1 | loss: 0.2378116
	speed: 0.0012s/iter; left time: 4.2010s
Epoch: 1 cost time: 0.850471019744873
Epoch: 1, Steps: 368 | Train Loss: 0.3365079 Vali Loss: 0.0883549 Test Loss: 0.9048560
Validation loss decreased (inf --> 0.088355).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.0610266
	speed: 0.0063s/iter; left time: 20.2926s
	iters: 200, epoch: 2 | loss: 0.1676964
	speed: 0.0012s/iter; left time: 3.6569s
	iters: 300, epoch: 2 | loss: 0.4586117
	speed: 0.0012s/iter; left time: 3.7102s
Epoch: 2 cost time: 0.6107399463653564
Epoch: 2, Steps: 368 | Train Loss: 0.3089999 Vali Loss: 0.0637310 Test Loss: 0.9004563
Validation loss decreased (0.088355 --> 0.063731).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.2944580
	speed: 0.0073s/iter; left time: 20.7606s
	iters: 200, epoch: 3 | loss: 0.1935845
	speed: 0.0014s/iter; left time: 3.7743s
	iters: 300, epoch: 3 | loss: 0.3456364
	speed: 0.0013s/iter; left time: 3.5341s
Epoch: 3 cost time: 0.6505739688873291
Epoch: 3, Steps: 368 | Train Loss: 0.3008569 Vali Loss: 0.0630094 Test Loss: 0.8917080
Validation loss decreased (0.063731 --> 0.063009).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.2785268
	speed: 0.0098s/iter; left time: 24.3297s
	iters: 200, epoch: 4 | loss: 0.2339821
	speed: 0.0014s/iter; left time: 3.3523s
	iters: 300, epoch: 4 | loss: 0.2680177
	speed: 0.0014s/iter; left time: 3.1760s
Epoch: 4 cost time: 0.8072638511657715
Epoch: 4, Steps: 368 | Train Loss: 0.2985411 Vali Loss: 0.0695905 Test Loss: 0.8795162
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.2230014
	speed: 0.0061s/iter; left time: 12.7859s
	iters: 200, epoch: 5 | loss: 0.2879477
	speed: 0.0012s/iter; left time: 2.3555s
	iters: 300, epoch: 5 | loss: 0.4403054
	speed: 0.0012s/iter; left time: 2.2478s
Epoch: 5 cost time: 0.5162820816040039
Epoch: 5, Steps: 368 | Train Loss: 0.2974286 Vali Loss: 0.0662711 Test Loss: 0.8827502
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.2102129
	speed: 0.0055s/iter; left time: 9.5263s
	iters: 200, epoch: 6 | loss: 0.2781702
	speed: 0.0012s/iter; left time: 1.9131s
	iters: 300, epoch: 6 | loss: 0.2376296
	speed: 0.0012s/iter; left time: 1.7940s
Epoch: 6 cost time: 0.517308235168457
Epoch: 6, Steps: 368 | Train Loss: 0.2968670 Vali Loss: 0.0669298 Test Loss: 0.8822278
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Space_5_DLinear_custom_ftS_sl60_ll30_pl30_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 837
mse:0.8917078971862793, mae:0.595669686794281, rse:0.8450361490249634, corr:[0.13943808 0.14199056 0.14226636 0.13966441 0.13461742 0.13235202
 0.13152261 0.13052909 0.12840107 0.12655172 0.12583861 0.12508711
 0.12432681 0.12332582 0.12275546 0.12236779 0.12114128 0.12053749
 0.11967915 0.11895817 0.11809193 0.11654375 0.11470943 0.11149887
 0.10919087 0.10781033 0.10672925 0.10509569 0.10297113 0.10208169]
